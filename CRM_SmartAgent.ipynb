{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMdCw8tYy2Sin1QyITYBTkm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Salilg3/RAG_CRM/blob/main/CRM_SmartAgent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q langchain-google-genai chromadb pandas matplotlib langchain_community seaborn google-generativeai"
      ],
      "metadata": {
        "id": "wBNcAaeZg4V_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "510fc5c0-de1f-41bd-8bf9-ae0f152f1ba5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/67.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m61.4/67.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.8/19.8 MB\u001b[0m \u001b[31m54.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m54.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m44.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.3/103.3 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.8/510.8 kB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m59.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.2/452.2 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"GOOGLE_API_KEY\"] = userdata.get('GOOGLE_API_KEY')\n",
        "API_KEY = userdata.get('GOOGLE_API_KEY')"
      ],
      "metadata": {
        "id": "lsRUxjlCjlfm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "Wha3CErEm1b0",
        "outputId": "93f833c9-7645-4fcd-c6be-fe2a78285ba0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-f7002f15-c5c7-4a1f-b87b-be8e5ba51017\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-f7002f15-c5c7-4a1f-b87b-be8e5ba51017\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving realestate_crm_bi.sql to realestate_crm_bi (1).sql\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import google.generativeai as genai\n",
        "from datetime import datetime\n",
        "import os\n",
        "import re\n",
        "\n",
        "plt.style.use('default')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "class SQL_Manange:\n",
        "  def __init__(self,db_path=\"crm_bi.db\"):\n",
        "      self.db_path= db_path\n",
        "      self.context_cache ={}\n",
        "\n",
        "  def setup_database(self, sql_file_path=\"realestate_crm_bi.sql\"):\n",
        "        try:\n",
        "            if not os.path.exists(sql_file_path):\n",
        "                raise FileNotFoundError(f\"SQL file '{sql_file_path}' not found. Please upload it first.\")\n",
        "\n",
        "            with open(sql_file_path, 'r', encoding='utf-8') as file:\n",
        "                sql_content = file.read()\n",
        "\n",
        "            conn = sqlite3.connect(self.db_path)\n",
        "            cursor = conn.cursor()\n",
        "            cursor.execute(\"PRAGMA foreign_keys = ON;\")\n",
        "            cursor.executescript(sql_content)\n",
        "            conn.commit()\n",
        "            conn.close()\n",
        "\n",
        "            self._verify_setup()\n",
        "            self._build_initial_query()\n",
        "            print(\"Database ready to use as context.\")\n",
        "            return True\n",
        "\n",
        "        except Exception as e:\n",
        "          print(f\"Database setup failed with a specific error: {e}\")\n",
        "          return False\n",
        "\n",
        "  def _verify_setup(self):\n",
        "        conn = sqlite3.connect(self.db_path)\n",
        "        cursor = conn.cursor()\n",
        "        tables = ['agents', 'customers', 'properties', 'transactions']\n",
        "        print(\"\\nDatabase Contents:\")\n",
        "        for table in tables:\n",
        "            cursor.execute(f\"SELECT COUNT(*) FROM {table}\")\n",
        "            count = cursor.fetchone()[0]\n",
        "            print(f\"  {table.capitalize()}: {count} records\")\n",
        "        conn.close()\n",
        "\n",
        "  def _build_initial_query(self):\n",
        "        conn = sqlite3.connect(self.db_path)\n",
        "        try:\n",
        "            regions_query = \"\"\"\n",
        "            SELECT a.region, COUNT(DISTINCT a.agent_id) as agent_count, COUNT(DISTINCT c.customer_id) as customer_count,\n",
        "                   COUNT(DISTINCT p.property_id) as property_count, COUNT(DISTINCT t.transaction_id) as transaction_count,\n",
        "                   ROUND(AVG(p.price), 2) as avg_property_price, SUM(t.amount) as total_revenue\n",
        "            FROM agents a\n",
        "            LEFT JOIN customers c ON a.region = c.region\n",
        "            LEFT JOIN properties p ON a.region = p.region\n",
        "            LEFT JOIN transactions t ON a.agent_id = t.agent_id\n",
        "            WHERE t.status = 'Completed'\n",
        "            GROUP BY a.region ORDER BY total_revenue DESC\n",
        "            \"\"\"\n",
        "            self.context_cache['regional_insights'] = pd.read_sql_query(regions_query, conn)\n",
        "\n",
        "            top_agents_query = \"SELECT name, region, specialization, total_sales, commission_rate FROM agents ORDER BY total_sales DESC LIMIT 10\"\n",
        "            self.context_cache['top_agents'] = pd.read_sql_query(top_agents_query, conn)\n",
        "\n",
        "            monthly_trends_query = \"\"\"\n",
        "            SELECT strftime('%Y-%m', transaction_date) as month, COUNT(*) as transaction_count,\n",
        "                   SUM(amount) as total_amount, AVG(amount) as avg_amount\n",
        "            FROM transactions WHERE status = 'Completed'\n",
        "            GROUP BY month ORDER BY month\n",
        "            \"\"\"\n",
        "            self.context_cache['market_trends'] = pd.read_sql_query(monthly_trends_query, conn)\n",
        "\n",
        "            property_insights_query = \"\"\"\n",
        "            SELECT property_type, COUNT(*) as count, AVG(price) as avg_price,\n",
        "                   MIN(price) as min_price, MAX(price) as max_price\n",
        "            FROM properties GROUP BY property_type ORDER BY avg_price DESC\n",
        "            \"\"\"\n",
        "            self.context_cache['property_insights'] = pd.read_sql_query(property_insights_query, conn)\n",
        "\n",
        "            customer_segments_query = \"\"\"\n",
        "            SELECT customer_type, budget_range, COUNT(*) as count, region\n",
        "            FROM customers GROUP BY customer_type, budget_range, region\n",
        "            ORDER BY count DESC\n",
        "            \"\"\"\n",
        "            self.context_cache['customer_segments'] = pd.read_sql_query(customer_segments_query, conn)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Context building warning: {e}\")\n",
        "\n",
        "        finally:\n",
        "            conn.close()\n",
        "  def execute_query(self, sql):\n",
        "        try:\n",
        "            conn = sqlite3.connect(self.db_path)\n",
        "            df = pd.read_sql_query(sql, conn)\n",
        "            conn.close()\n",
        "            return df\n",
        "        except Exception as e:\n",
        "            return f\"SQL Error: {e}\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class LLM_Handling:\n",
        "    def __init__(self,api_key):\n",
        "        self.llm = None\n",
        "        try:\n",
        "            generation_config= {\n",
        "                \"temperature\": 0.2,\n",
        "                \"max_output_tokens\": 1024 }\n",
        "            genai.configure(api_key=api_key)\n",
        "            self.llm = genai.GenerativeModel(\n",
        "              'gemini-1.5-flash',\n",
        "              generation_config=generation_config\n",
        "                                            )\n",
        "        except Exception as e:\n",
        "            print(f\"Gemini setup failed: {e}\")\n",
        "\n",
        "    def generate_sql_with_rag(self, user_query, relevant_context):\n",
        "        schema_context = \"\"\"\n",
        "        You are a SQL expert for a Real Estate CRM system with RAG enhancement.\n",
        "        Provide a detailed, data-driven answer. If the question involves numbers or comparisons, be specific with figures and round them off to the nearest hundred if more than 5 digits in the figure.\n",
        "        Database schema:\n",
        "        TABLES:\n",
        "        1. agents (agent_id, name, email, phone, region, specialization, hire_date, commission_rate, total_sales, status)\n",
        "        2. customers (customer_id, name, email, phone, region, customer_type, budget_range, registration_date, last_activity_date, status)\n",
        "        3. properties (property_id, address, region, property_type, bedrooms, price, square_feet, listing_date, status, agent_id)\n",
        "        4. transactions (transaction_id, customer_id, property_id, agent_id, transaction_date, transaction_type, amount, commission, status)\n",
        "        RULES:\n",
        "        1. Generate ONLY valid SQLite queries.\n",
        "        2. If user wants charts, return \"CHART:\" + SQL query.\n",
        "        3. For scatter plots, ensure query returns 2 numeric columns.\n",
        "        4. For funnel charts, order data in descending stages.\n",
        "        5. Use the contextual insights provided to generate more accurate queries.\n",
        "        6. Return only SQL, no explanations.\n",
        "        7. CRITICAL: The query MUST begin with 'SELECT' or 'WITH'. Do not add any other text before the SQL query.\n",
        "        \"\"\"\n",
        "        rag_prompt = f\"\"\"\n",
        "        {schema_context}\n",
        "        RETRIEVED CONTEXTUAL DATA (Use this to inform your SQL generation):\n",
        "        {relevant_context}\n",
        "        User Query: {user_query}\n",
        "        Based on the above context and user query, generate the most appropriate SQL query:\n",
        "        \"\"\"\n",
        "        try:\n",
        "            response = self.llm.generate_content(rag_prompt)\n",
        "            return response.text.strip()\n",
        "        except Exception as e:\n",
        "            return f\"AI Error: {e}\"\n",
        "\n",
        "    def generate_rag_insights(self, query_result, user_query,relevant_context):\n",
        "        if isinstance(query_result, str) or query_result.empty:\n",
        "            return \"No insights available.\"\n",
        "\n",
        "        insights_prompt = f\"\"\"\n",
        "        Based on the following query results and contextual data, provide key business insights:\n",
        "        USER QUERY: {user_query}\n",
        "        QUERY RESULTS:\n",
        "        {query_result.to_string(index=False)}\n",
        "        BUSINESS CONTEXT:\n",
        "        {relevant_context}\n",
        "        Provide 3-4 key insights in numbered point that would be valuable for real estate business decision making and make the data analysis short and concise for the user:\n",
        "        \"\"\"\n",
        "        try:\n",
        "            response = self.llm.generate_content(insights_prompt)\n",
        "            return response.text.strip()\n",
        "        except Exception as e:\n",
        "            return f\"Insights generation error: {e}\"\n",
        "\n",
        "class Main_Execution:\n",
        "    def __init__(self,api_key):\n",
        "        self.db_manager = SQL_Manange()\n",
        "        self.llm_client = LLM_Handling(api_key)\n",
        "        self.chart_generator = Chart_Generator()\n",
        "\n",
        "    def setup(self, sql_file = \"realestate_crm_bi.sql\"):\n",
        "      return self.db_manager.setup_database(sql_file)\n",
        "\n",
        "    def enhanced_query_context(self, user_query):\n",
        "        relevant_context = []\n",
        "        query_lower = user_query.lower()\n",
        "\n",
        "        if any(word in query_lower for word in ['region', 'mumbai', 'bangalore', 'pune', 'delhi', 'chennai']):\n",
        "            regional_data = self.db_manager.context_cache.get('regional_insights')\n",
        "            if regional_data is not None and not regional_data.empty:\n",
        "                relevant_context.append(\"REGIONAL INSIGHTS:\")\n",
        "                relevant_context.append(regional_data.head().to_string(index=False))\n",
        "                relevant_context.append(\"\")\n",
        "\n",
        "        if any(word in query_lower for word in ['agent', 'performance', 'sales', 'top', 'best']):\n",
        "            agent_data = self.db_manager.context_cache.get('top_agents')\n",
        "            if agent_data is not None and not agent_data.empty:\n",
        "                relevant_context.append(\"TOP AGENT PERFORMANCE:\")\n",
        "                relevant_context.append(agent_data.head().to_string(index=False))\n",
        "                relevant_context.append(\"\")\n",
        "\n",
        "        if any(word in query_lower for word in ['trend', 'monthly', 'time', 'period', 'growth']):\n",
        "            trend_data = self.db_manager.context_cache.get('market_trends')\n",
        "            if trend_data is not None and not trend_data.empty:\n",
        "                relevant_context.append(\"MARKET TRENDS:\")\n",
        "                relevant_context.append(trend_data.tail().to_string(index=False))\n",
        "                relevant_context.append(\"\")\n",
        "\n",
        "        if any(word in query_lower for word in ['property', 'price', 'apartment', 'villa', 'office']):\n",
        "            property_data = self.db_manager.context_cache.get('property_insights')\n",
        "            if property_data is not None and not property_data.empty:\n",
        "                relevant_context.append(\"PROPERTY MARKET INSIGHTS:\")\n",
        "                relevant_context.append(property_data.to_string(index=False))\n",
        "                relevant_context.append(\"\")\n",
        "\n",
        "        if any(word in query_lower for word in ['customer', 'client', 'buyer', 'budget']):\n",
        "            customer_data = self.db_manager.context_cache.get('customer_segments')\n",
        "            if customer_data is not None and not customer_data.empty:\n",
        "                relevant_context.append(\"CUSTOMER SEGMENTS:\")\n",
        "                relevant_context.append(customer_data.head(10).to_string(index=False))\n",
        "                relevant_context.append(\"\")\n",
        "\n",
        "        return \"\\n\".join(relevant_context)\n",
        "\n",
        "    def process_output(self, user_query):\n",
        "        print(\"\\n\" + \"=\"*100)\n",
        "        print(f\"Processing Query: {user_query}\")\n",
        "        print(\"=\"*100)\n",
        "        context = self.enhanced_query_context(user_query)\n",
        "        ai_response = self.llm_client.generate_sql_with_rag(user_query,context)\n",
        "\n",
        "        is_chart = ai_response.startswith(\"CHART:\")\n",
        "        if is_chart:\n",
        "            ai_response = ai_response.replace(\"CHART:\", \"\", 1).strip()\n",
        "        sql_query = \"\"\n",
        "        match = re.search(r\"```sql(.*?)```\", ai_response, re.DOTALL)\n",
        "\n",
        "        if match:\n",
        "            sql_query = match.group(1).strip()\n",
        "        else:\n",
        "            sql_query = ai_response.strip()\n",
        "\n",
        "        if not sql_query:\n",
        "            print(\"AI did not return a valid SQL query.\")\n",
        "            return\n",
        "        print(f\"\\nGenerated SQL Query:\")\n",
        "        print(\"-\" * 50)\n",
        "        print(sql_query)\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "        result = self.db_manager.execute_query(sql_query)\n",
        "\n",
        "        if isinstance(result, str):\n",
        "            print(result)\n",
        "            return\n",
        "\n",
        "        if result.empty:\n",
        "            print(\"No results found\")\n",
        "            return\n",
        "\n",
        "        print(f\"\\nQuery Results ({len(result)} records):\")\n",
        "        print(\"=\" * 100)\n",
        "        print(result.to_string(index=False))\n",
        "\n",
        "        print(\"\\nInsights Based on the data feeded and query:\")\n",
        "        print(\"=\" * 100)\n",
        "        insights = self.llm_client.generate_rag_insights(result, user_query, context)\n",
        "        print(insights)\n",
        "\n",
        "        if is_chart or any(word in user_query.lower() for word in ['chart', 'graph', 'plot', 'bar', 'pie', 'line', 'scatter', 'funnel']):\n",
        "            chart_type = self.chart_generator.select_chart(user_query)\n",
        "            print(f\"\\nCreating {chart_type.upper()} chart...\")\n",
        "            self.chart_generator.create_graph(result, chart_type,f\"Your Desired Graph/Chart\")\n",
        "        print(\"\\n\" + \"=\"*100)\n",
        "\n",
        "class Chart_Generator:\n",
        "  def select_chart(self, user_query):\n",
        "\n",
        "        query_lower = user_query.lower()\n",
        "        if 'line chart' in query_lower or 'line graph' in query_lower or 'trend' in query_lower:\n",
        "            return 'line'\n",
        "        elif 'scatter plot' in query_lower or 'scatter chart' in query_lower or 'correlation' in query_lower:\n",
        "            return 'scatter'\n",
        "        elif 'pie chart' in query_lower or 'pie graph' in query_lower:\n",
        "            return 'pie'\n",
        "        elif 'funnel chart' in query_lower or 'funnel graph' in query_lower or 'conversion' in query_lower:\n",
        "            return 'funnel'\n",
        "        elif 'bar chart' in query_lower or 'bar graph' in query_lower or 'comparison' in query_lower:\n",
        "            return 'bar'\n",
        "        else:\n",
        "            return 'bar'\n",
        "  def create_graph(self, df, chart_type, title):\n",
        "        if df.empty:\n",
        "            print(\"No data to visualize\")\n",
        "            return\n",
        "        plt.figure(figsize=(14, 8))\n",
        "        x_col, y_col = None, None\n",
        "        for col in df.columns:\n",
        "          if x_col is None and pd.api.types.is_string_dtype(df[col]):\n",
        "              x_col = col\n",
        "          if y_col is None and pd.api.types.is_numeric_dtype(df[col]):\n",
        "              y_col = col\n",
        "\n",
        "        if x_col is None: ## For scatter plot since both are numbers in this case.\n",
        "          x_col = df.columns[0]\n",
        "        if y_col is None:\n",
        "          y_col = df.columns[1] if len(df.columns) > 1 else df.columns[0]\n",
        "\n",
        "        if chart_type == 'bar':\n",
        "            bars = plt.bar(df[x_col], df[y_col], color='steelblue', alpha=0.8, edgecolor='navy')\n",
        "            plt.xticks(rotation=45, ha='right')\n",
        "            for bar in bars:\n",
        "                height = bar.get_height()\n",
        "                plt.text(bar.get_x() + bar.get_width()/2., height, f'{height:,.0f}', ha='center', va='bottom', fontsize=9)\n",
        "            plt.ylabel(y_col.replace('_', ' ').title())\n",
        "            plt.xlabel(x_col.replace('_', ' ').title())\n",
        "\n",
        "        elif chart_type == 'line':\n",
        "            plt.plot(df[x_col], df[y_col], marker='o', linewidth=3, markersize=8, color='steelblue')\n",
        "            plt.xticks(rotation=45, ha='right')\n",
        "            plt.grid(True, alpha=0.3)\n",
        "            plt.ylabel(y_col.replace('_', ' ').title())\n",
        "            plt.xlabel(x_col.replace('_', ' ').title())\n",
        "\n",
        "        elif chart_type == 'scatter':\n",
        "            if len(df.columns) >= 2:\n",
        "                plt.scatter(df[x_col], df[y_col], alpha=0.7, s=100, color='steelblue', edgecolor='navy')\n",
        "                plt.xlabel(x_col.replace('_', ' ').title())\n",
        "                plt.ylabel(y_col.replace('_', ' ').title())\n",
        "                plt.grid(True, alpha=0.3)\n",
        "                try:\n",
        "                    correlation = df[x_col].corr(df[y_col])\n",
        "                    plt.text(0.05, 0.95, f'Correlation: {correlation:.2f}', transform=plt.gca().transAxes, fontsize=12,\n",
        "                             bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"yellow\", alpha=0.7))\n",
        "                except:\n",
        "                    pass\n",
        "            else:\n",
        "                print(\"Scatter plot requires 2 numeric columns\")\n",
        "                return\n",
        "\n",
        "        elif chart_type == 'pie':\n",
        "            colors = plt.cm.Set3(np.linspace(0, 1, len(df)))\n",
        "            wedges, texts, autotexts = plt.pie(df[y_col], labels=df[x_col], autopct='%1.1f%%', startangle=90, colors=colors)\n",
        "            plt.axis('equal')\n",
        "            for text in texts:\n",
        "                text.set_fontsize(10)\n",
        "            for autotext in autotexts:\n",
        "                autotext.set_color('white')\n",
        "                autotext.set_fontweight('bold')\n",
        "\n",
        "        elif chart_type == 'funnel':\n",
        "            if len(df.columns) >= 2:\n",
        "                df['label'] = df.iloc[:, 0].astype(str) + ' - ' + df.iloc[:, 1].astype(str)\n",
        "                value_col = df.columns[-2]\n",
        "                labels = df['label']\n",
        "                values = df[value_col]\n",
        "                sort_indices = values.argsort()[::-1]\n",
        "                labels = labels[sort_indices]\n",
        "                values = values[sort_indices]\n",
        "                y_pos = np.arange(len(labels))\n",
        "                bars = plt.barh(y_pos, values, color='steelblue', alpha=0.8)\n",
        "                plt.yticks(y_pos, labels)\n",
        "                plt.xlabel(value_col.replace('_', ' ').title())\n",
        "\n",
        "                for i, bar in enumerate(bars):\n",
        "                    width = bar.get_width()\n",
        "                    plt.text(width + values.max() * 0.01, bar.get_y() + bar.get_height()/2,\n",
        "                             f'{width:,.0f}', ha='left', va='center', fontsize=10, fontweight='bold')\n",
        "\n",
        "                plt.gca().invert_yaxis()\n",
        "            else:\n",
        "                print(\"Funnel chart requires at least two columns (category and value).\")\n",
        "                return\n",
        "\n",
        "        plt.title(title, fontsize=16, fontweight='bold', pad=20)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "\n",
        "def input_user_query():\n",
        "    print(\"=\" * 100)\n",
        "    print(\"AI Agent for CRM Data\")\n",
        "    print(\"=\" * 100)\n",
        "    alpha = Main_Execution(api_key=API_KEY)\n",
        "\n",
        "    if not alpha.setup():\n",
        "        print(\"Failed to setup database. Make sure the SQL file is uploaded.\")\n",
        "        return\n",
        "\n",
        "    print(\"\\nEnter your query and specify what type of graph/chart if needed:\")\n",
        "    user_query = input(\"Your Query: \").strip()\n",
        "    if not user_query:\n",
        "        print(\"Query required\")\n",
        "        return\n",
        "\n",
        "    alpha.process_output(user_query)\n",
        "    print(\"\\nQuery completed!\\nTo run another query, execute the cell again or call input_user_query()\")"
      ],
      "metadata": {
        "id": "ViRVvrxujwGQ"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_user_query()"
      ],
      "metadata": {
        "id": "L0vjeEBXmbyY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 506
        },
        "outputId": "0bb05ae8-9515-4a1e-e83f-d5cfe4de8532"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "====================================================================================================\n",
            "AI Agent for CRM Data\n",
            "====================================================================================================\n",
            "\n",
            "Database Contents:\n",
            "  Agents: 15 records\n",
            "  Customers: 40 records\n",
            "  Properties: 60 records\n",
            "  Transactions: 80 records\n",
            "Database ready to use as context.\n",
            "\n",
            "Enter your query and specify what type of graph/chart if needed:\n",
            "Your Query: Make a scatter plot of transaction amount and agent commision in the year 2024-25\n",
            "\n",
            "====================================================================================================\n",
            "Processing Query: Make a scatter plot of transaction amount and agent commision in the year 2024-25\n",
            "====================================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 2049.18ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Generated SQL Query:\n",
            "--------------------------------------------------\n",
            "AI Error: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
            "--------------------------------------------------\n",
            "SQL Error: Execution failed on sql 'AI Error: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.': near \"AI\": syntax error\n",
            "\n",
            "Query completed!\n",
            "To run another query, execute the cell again or call input_user_query()\n"
          ]
        }
      ]
    }
  ]
}